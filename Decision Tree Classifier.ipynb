{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cf8f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    \n",
    "    def __init__(self, max_depth, min_samples=2, impurity = \"gini\"):\n",
    "        self.tree = None\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples = min_samples\n",
    "        if impurity in [\"gini\", \"entropy\"]:\n",
    "            self.impurity = impurity\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid impurity: {impurity}. Use 'entropy' or 'gini' instead.\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def gini(y):\n",
    "        imp = 1\n",
    "        total = len(y)\n",
    "        counts = Counter(y)\n",
    "        for cat, count in counts.items():\n",
    "            p = count/total\n",
    "            imp -= p**2\n",
    "        \n",
    "        return imp\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def entropy(y):\n",
    "        total = len(y)\n",
    "        imp = 0\n",
    "        counts = Counter(y)\n",
    "        for cat, count in counts.items():\n",
    "            p = count/total\n",
    "            logp = p*math.log2(p)\n",
    "            imp -= logp\n",
    "        return imp\n",
    "    \n",
    "    def information_gain(self, y,split):\n",
    "        y_np = y.to_numpy()\n",
    "        total = len(y_np)\n",
    "        parent = self.gini(y) if self.impurity == \"gini\" else self.entropy(y)\n",
    "        if self.impurity == \"gini\":\n",
    "            weighted = sum([(len(idx)/total)*self.gini(y_np[idx]) for idx in split])\n",
    "        else:\n",
    "            weighted = sum([(len(idx)/total)*self.entropy(y_np[idx]) for idx in split])\n",
    "        return parent - weighted\n",
    "    \n",
    "    \n",
    "    def best_split(self,X,y):\n",
    "        \n",
    "        # What are X and Y here? For the first node, it is the entire dataset; X being the input and y being the target\n",
    "        # When we check the information gain in the first node, the target y becomes the parent and based on splits in different features, increment in purity is calculated\n",
    "        # for subsequent nodes; X and y will only contain a subset of the dataset, all the features will be included\n",
    "        n_samples, n_features = X.shape\n",
    "        gain = 0\n",
    "        thres = None # float value; Only in case of numerical feature\n",
    "        feat = None # we will keep it as an integer, whenever we are using this to refer to a colummn in a DF, we will use iloc method\n",
    "        split = None # This will be a list of indices. In case of numerical features, split indices will be identified by a threshold value. In case of categorical feature, the split indices will be identified by indices of each category in that feature\n",
    "        for i in range(n_features):\n",
    "            x = X.iloc[:, i]\n",
    "            \n",
    "            x = x.to_numpy()\n",
    "            \n",
    "            if np.issubdtype(x.dtype, np.number):\n",
    "                idx = np.argsort(x)\n",
    "                x_sort = x[idx]\n",
    "                \n",
    "                for j in range(1,n_samples):\n",
    "                    if(x_sort[j] == x_sort[j-1]):\n",
    "                        continue\n",
    "                        \n",
    "                    th = (x_sort[j] + x_sort[j-1])/2.0\n",
    "                    left = np.where(x<=th)[0]\n",
    "                    right = np.where(x>th)[0]\n",
    "                    split_temp = [left, right]\n",
    "                    new_gain = self.information_gain(y, split_temp)\n",
    "                    if new_gain > gain:\n",
    "                        gain = new_gain\n",
    "                        thres = th\n",
    "                        split = split_temp\n",
    "                        feat = i\n",
    "            else:\n",
    "                classes = np.unique(x)\n",
    "                split_temp = [np.where(x==clas)[0] for clas in classes]\n",
    "                new_gain = self.information_gain(y, split_temp)\n",
    "                if new_gain > gain:\n",
    "                    gain = new_gain\n",
    "                    thres = None\n",
    "                    split = split_temp\n",
    "                    feat = i\n",
    "                    \n",
    "        return feat, thres, split, gain\n",
    "            \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    def fit(self, X, y):\n",
    "        self.tree = self.build(X,y,depth=0)\n",
    "        \n",
    "    def build(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        counts = Counter(y)\n",
    "        pred_class = max(counts, key=counts.get)\n",
    "        \n",
    "        node = {\n",
    "            \"pred\": pred_class,\n",
    "            \"feature\": None,\n",
    "            \"threshold\": None,\n",
    "            \"split\": None,\n",
    "            \"children\": []\n",
    "        }\n",
    "        \n",
    "        feat, thres, split, gain = self.best_split(X,y)\n",
    "        \n",
    "        node.update({\"feature\": feat, \"threshold\": thres, \"split\": split})\n",
    "        \n",
    "        if gain <= 0:\n",
    "            return node\n",
    "        \n",
    "        if thres is None:\n",
    "            x = X.iloc[:, feat]\n",
    "            x = x.to_numpy()\n",
    "            classes = np.unique(x)\n",
    "            for clas in classes:\n",
    "                idx = np.where(x == clas)[0]\n",
    "                child = self.build(X.iloc[idx], y.iloc[idx], depth+1)\n",
    "                node[\"children\"].append((clas,child))\n",
    "        else:\n",
    "            left = split[0]\n",
    "            right = split[1]\n",
    "            child1 = self.build(X.iloc[left], y.iloc[left])\n",
    "            child2 = self.build(X.iloc[right], y.iloc[right])\n",
    "            node[\"children\"].append((\"<=\", child1))\n",
    "            node[\"children\"].append((\">\", child2))\n",
    "            \n",
    "        return node\n",
    "    \n",
    "    def predict(self, X):\n",
    "        x_np = X.to_numpy()\n",
    "        out = [self.predict_one(row, self.tree) for row in x_np]\n",
    "        return out\n",
    "    \n",
    "    def predict_one(self, row, node):\n",
    "        if node[\"children\"] == []:\n",
    "            return node[\"pred\"]\n",
    "        if node[\"threshold\"] == None:\n",
    "            for cat, child in node[\"children\"]:\n",
    "                if row[node[\"feature\"]] == cat:\n",
    "                    return self.preidct_one(row, child)\n",
    "        else:\n",
    "            if row[node[\"feature\"]] <= node[\"threshold\"]:\n",
    "                return self.predict_one(row, node[\"children\"][0][1])\n",
    "            else:\n",
    "                return self.predict_one(row, node[\"children\"][1][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
